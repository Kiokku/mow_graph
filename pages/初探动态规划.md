- > https://www.hello-algo.com/chapter_dynamic_programming/intro_to_dynamic_programming/
-
- **「动态规划 Dynamic Programming」**是一种通过将复杂问题分解为更简单的子问题的方式来求解问题的方法。它将一个问题分解为一系列更小的子问题，并通过存储子问题的解来避免重复计算，从而大幅提升时间效率。
- > ❓ 爬楼梯
  >
  > 给定一个共有 $n$ 阶的楼梯，你每步可以上 1 阶或者 2 阶，请问有多少种方案可以爬到楼顶。
- ![image.png](../assets/image_1689154160717_0.png)
- 本题的目标是求解方案数量，**我们可以考虑通过回溯来穷举所有可能性**。具体来说，将爬楼梯想象为一个多轮选择的过程：[[#blue]]==从地面出发，每轮选择上 1 阶或 2 阶，每当到达楼梯顶部时就将方案数量加 1 ，当越过楼梯顶部时就将其剪枝。==
-
- ## 方法一：暴力搜索
	- 对于本题，我们可以尝试将问题拆解为更小的子问题。设爬到第 $i$ 阶共有 $dp[i]$ 种方案，那么 $dp[i]$ 就是原问题，其子问题包括:
	- $$dp[i-1], dp[i-2], dp[i-3], \cdots, dp[2], dp[1]$$
	- 由于每轮只能上 1 阶或 2 阶，因此当我们站在第 $i$ 阶楼梯上时，上一轮只可能站在第 $i−1$ 阶或第 $i−2$ 阶上。因此，**爬到第 $i−1$ 阶的方案数加上爬到第 $i−2$ 阶的方案数就等于爬到第 $i$ 阶的方案数**，即：
	- $$dp[i] = dp[i-1]+dp[i-2]$$
	- 也就是说，在爬楼梯问题中，**各个子问题之间不是相互独立的，原问题的解可以由子问题的解构成**。
	- 我们可以基于此递推公式写出暴力搜索代码：以 $dp[n]$ 为起始点，**从顶至底地将一个较大问题拆解为两个较小问题的和**，直至到达最小子问题 $dp[1]$ 和 $dp[2]$ 时返回。其中，最小子问题的解 $dp[1]=1 , dp[2]=2$ 是已知的，代表爬到第 1 , 2 阶分别有 1 , 2 种方案。
	- ```
	  /* 搜索 */
	  function dfs(i) {
	      // 已知 dp[1] 和 dp[2] ，返回之
	      if (i == 1 || i == 2)
	          return i;
	      // dp[i] = dp[i-1] + dp[i-2]
	      const count = dfs(i - 1) + dfs(i - 2);
	      return count;
	  }
	  
	  /* 爬楼梯：搜索 */
	  function climbingStairsDFS(n) {
	      return dfs(n);
	  }
	  ```
	- 它和标准回溯代码都属于**深度优先搜索**，但更加简洁。
	- 对于问题 $dp[n]$ ，其递归树的深度为 $n$ ，时间复杂度为 $O(2^n)$ 。指数阶的运行时间增长地非常快，如果我们输入一个比较大的 $n$ ，则会陷入漫长的等待之中。
	- 实际上，**指数阶的时间复杂度是由于「重叠子问题」导致的**
- ## 方法二：记忆化搜索
	- 为了提升算法效率，**我们希望所有的重叠子问题都只被计算一次**。具体来说，考虑借助一个数组 `mem` 来记录每个子问题的解，并在搜索过程中这样做：
		- 当首次计算 $dp[i]$ 时，我们将其记录至 `mem[i]` ，以便之后使用；
		- 当再次需要计算 $dp[i]$ 时，我们便可直接从 `mem[i]` 中获取结果，从而将重叠子问题剪枝；
	- ```
	  /* 搜索 */
	  function dfs(i, mem) {
	      // 已知 dp[1] 和 dp[2] ，返回之
	      if (i == 1 || i == 2)
	          return i;
	      // dp[i] = dp[i-1] + dp[i-2]
	      if (mem[i] != -1) {
	          return mem[i];
	      }
	      const count = dfs(i - 1, mem) + dfs(i - 2, mem);
	      mem[i] = count;
	      return count;
	  
	  }
	  
	  /* 爬楼梯：搜索 */
	  function climbingStairsDFS(n) {
	      const mem = Array(n+1).fill(-1);
	      return dfs(n, mem);
	  }
	  ```
	- **经过记忆化处理后，所有重叠子问题都只需被计算一次，时间复杂度被优化至** $O(n)$
- ## 方法三：动态规划
	- **记忆化搜索是一种“从顶至底”的方法**：我们从原问题（根节点）开始，递归地将较大子问题分解为较小子问题，直至解已知的最小子问题（叶节点）；最终通过回溯将子问题的解逐层收集，得到原问题的解。
	- **我们也可以直接“从底至顶”进行求解**，得到标准的动态规划解法[[#green]]==：从最小子问题开始，迭代地求解较大子问题，直至得到原问题的解。==
	- > 由于动态规划不包含回溯过程，因此无需使用递归，而可以直接基于递推实现。我们初始化一个数组 `dp` 来存储子问题的解，从最小子问题开始，逐步求解较大子问题。数组 `dp` 起到了记忆化搜索中数组 `mem` 相同的记录作用。
	- ```
	  /* 爬楼梯：动态规划 */
	  function climbingStairsDP(n) {
	      if (n == 1 || n == 2)
	          return n;
	      // 初始化 dp 表，用于存储子问题的解
	      const dp = new Array(n + 1);
	      // 初始状态：预设最小子问题的解
	      dp[1] = 1;
	      dp[2] = 2;
	      // 状态转移：从较小子问题逐步求解较大子问题
	      for (let i = 3; i <= n; i++) {
	          dp[i] = dp[i - 1] + dp[i - 2];
	      }
	      return dp[n];
	  }
	  ```
	- 与回溯算法一样，动态规划也使用“状态”概念来表示问题求解的某个特定阶段，每个状态都对应一个子问题以及相应的局部最优解。例如对于爬楼梯问题，状态定义为当前所在楼梯阶数 $i$ 。**动态规划的常用术语包括**：
		- 将数组 `dp` 称为$「dp表」$，$dp[i]$ 表示状态 $i$ 对应子问题的解；
		- 将最小子问题对应的状态（即第 1 , 2 阶楼梯）称为**「初始状态」**；
		- 将递推公式 $dp[i]=dp[i−1]+dp[i−2]$ 称为**「状态转移方程」**；
	- 细心的你可能发现，**由于** $dp[i]$ **只与** $dp[i-1]$ **和** $dp[i-2]$ **有关，因此我们无需使用一个数组 `dp` 来存储所有子问题的解**，而只需两个变量滚动前进即可。如以下代码所示，由于省去了数组 `dp` 占用的空间，因此空间复杂度从 $O(n)$ 降低至 $O(1)$ 。
	- ```
	  /* 爬楼梯：状态压缩后的动态规划 */
	  function climbingStairsDPComp(n) {
	      if (n == 1 || n == 2)
	          return n;
	      const a = 1, b = 2;
	      for (let i = 3; i <= n; i++) {
	          const tmp = b;
	          b = a + b;
	          a = tmp;
	      }
	      return b;
	  }
	  ```
	- **我们将这种空间优化技巧称为「状态压缩」**
	- [[#green]]==子问题分解是一种通用的算法思路==，在**分治算法**、**动态规划**、**回溯算法**中各有特点：
		- **分治算法**将原问题划分为几个独立的子问题，然后递归解决子问题，最后合并子问题的解得到原问题的解。例如，归并排序将长数组不断划分为两个短子数组，再将排序好的子数组合并为排序好的长数组。
		- **动态规划**也是将原问题分解为多个子问题，但与分治算法的主要区别是，**动态规划中的子问题往往不是相互独立的**，原问题的解依赖于子问题的解，而子问题的解又依赖于更小的子问题的解。因此，动态规划通常会引入记忆化，保存已经解决的子问题的解，避免重复计算。
		- **回溯算法**在尝试和回退中穷举所有可能的解，并通过剪枝避免不必要的搜索分支。原问题的解由一系列决策步骤构成，我们可以将每个决策步骤之后的剩余问题看作为一个子问题。